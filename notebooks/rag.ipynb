{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1e11b2-38f4-4595-8a2c-c02cd2a11f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.extend([os.getcwd(),'..'])\n",
    "\n",
    "from config  import CONFIG\n",
    "\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b461e80-5a6b-487b-ae1e-1082852b9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(CONFIG.QDRANT_SERVER_URL)\n",
    "\n",
    "def search(query, limit=5):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=CONFIG.QDRANT_COLLECTION_NAME,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=CONFIG.EMBEDDING_MODEL \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True, #to get metadata in the results\n",
    "        with_vectors=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# result=search(query)\n",
    "# result.points[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf73b46-54ca-4f47-a3c4-64169da4fa56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9052136 ResNet architecture [16] (a) to generate a rich, multi-scale convolutional feature pyramid (b). To this backbone RetinaNet attaches two\n",
      "subnetworks, one for classifying anchor boxes (c) and one for regressing from anchor boxes to ground-truth object boxes (d). The network\n",
      "design is intentionally simple, which enables this work to focus on a novel focal loss function that eliminates the accuracy gap between our \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.8839458 ResNet architecture (middle). We train multiple small net-\n",
      "works with varying depths on C10+ and plot their test ac-\n",
      "curacies as a function of network parameters. In com-\n",
      "parison with other popular network architectures, such as\n",
      "AlexNet [16] or VGG-net [29], ResNets with pre-activation\n",
      "use fewer parameters while typically achieving better re-\n",
      "sults [12]. Hence, we compare DenseNet ( k = 12) against\n",
      "this architecture. The training setting for DenseNet is kept\n",
      "the same as in the previous section.\n",
      "The graph shows that DenseNet-BC is consistently the\n",
      "most parameter efﬁcient variant of DenseNet. Further, to\n",
      "achieve the same level of accuracy, DenseNet-BC only re-\n",
      "quires around 1/3 of the parameters of ResNets (middle\n",
      "plot). This result is in line with the results on ImageNet\n",
      "we presented in Figure 3. The right plot in Figure 4 shows\n",
      "that a DenseNet-BC with only 0.8M trainable parameters\n",
      "is able to achieve comparable accuracy as the 1001-layer \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.8827074 ResNet Architecture CIFAR-10 CIFAR-100\n",
      "(a) Pre-activation [8] 5.82 25.06\n",
      "(b) Removing the ﬁrst ReLU 5.31 24.55\n",
      "(c) BN after the ﬁnal conv 5.74 24.54\n",
      "(d) (b) + (c) 5.29 23.74\n",
      "PyramidNet Architecture CIFAR-10 CIFAR-100\n",
      "(a) Pre-activation [8] 5.15 24.40\n",
      "(b) Removing the ﬁrst ReLU 4.81 23.43\n",
      "(c) BN after the ﬁnal conv 4.96 23.89\n",
      "(d) (b) + (c) 4.62 23.31\n",
      "PyramidNet (bottleneck) Architecture CIFAR-10 CIFAR-100\n",
      "(a) Pre-activation [8] 4.61 21.10\n",
      "(b) Removing the ﬁrst ReLU 4.45 20.40\n",
      "(c) BN after the ﬁnal conv 4.56 20.44\n",
      "(d) (b) + (c) 4.26 20.32\n",
      "Table 3. Top-1 errors (%) on CIFAR datasets for several build-\n",
      "ing block combinations of ReLUs and BN layers shown in Fig-\n",
      "ure 6 (a)–(d), using ResNet [8] (with original feature map dimen-\n",
      "sion conﬁguration) and our PyramidNet.\n",
      "of freedom obtained by involvingγand βfrom the BN lay-\n",
      "ers could improve the capability of the network architecture.\n",
      "The results in Table 3 support the conclusion that adding a \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.8788274 to ResNet, ResNeXt [31] improves modeling capacity by increasing ‘cardinality’\n",
      "of ResNet. It is implemented by using group convolutions. In practice, increas-\n",
      "ing cardinality increases runtime in modern deep learning frameworks. Moreover,\n",
      "squeeze-and-excitation network (SENet) [12] introduces channel wise attention\n",
      "into ResNet. It achieves better performance on ImageNet compared to ResNet,\n",
      "but it also increases number of network parameters and computations. The re-\n",
      "cently proposed densely connected networks (DenseNet) [13] uses concatenation\n",
      "to replace short-cut connections. It was proved to be more eﬃcient than ResNet.\n",
      "However, there are two limitations in the above CNN architectures. Firstly,\n",
      "the limited basic modules prevent them from gaining more appealing properties.\n",
      "For example, all these architectures are simply composed of convolutions, BNs,\n",
      "ReLUs, and poolings. The only diﬀerence among them is how these modules \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.878734 methods.\n",
      "3. Network Architecture\n",
      "Refer to the overall network architecture shown in Fig-\n",
      "ure\n",
      "1. Similar to SSD [ 29], ReﬁneDet is based on a feed-\n",
      "forward convolutional network that produces a ﬁxed num-\n",
      "ber of bounding boxes and the scores indicating the pres-\n",
      "ence of different classes of objects in those boxes, followed\n",
      "by the non-maximum suppression to produce the ﬁnal re-\n",
      "sult. ReﬁneDet is formed by two inter-connected modules,\n",
      "i.e., the ARM and the ODM. The ARM aims to remove neg- \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.8762709 ResNet architecture [16] (a) to generate a rich, multi-scale convolutional feature pyramid (b). To this backbone RetinaNet attaches two\n",
      "subnetworks, one for classifying anchor boxes (c) and one for regressing from anchor boxes to ground-truth object boxes (d). The network\n",
      "design is intentionally simple, which enables this work to focus on a novel focal loss function that eliminates the accuracy gap between our\n",
      "one-stage detector and state-of-the-art two-stage detectors like Faster R-CNN with FPN [20] while running at faster speeds.\n",
      "Classiﬁcation Subnet: The classiﬁcation subnet predicts\n",
      "the probability of object presence at each spatial position\n",
      "for each of the Aanchors and Kobject classes. This subnet\n",
      "is a small FCN attached to each FPN level; parameters of\n",
      "this subnet are shared across all pyramid levels. Its design\n",
      "is simple. Taking an input feature map with C channels\n",
      "from a given pyramid level, the subnet applies four 3 ×3\n",
      "conv layers, each withCﬁlters and each followed by ReLU \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.8729619 based on the Cityscapes test set. Qualitative results are\n",
      "shown in Figure 7, in Appendix C, and in our result video2.\n",
      "5.1. Residual Network Baseline\n",
      "Our network architecture can be described as a\n",
      "ResNet [25] encoder/decoder architecture, where the resid-\n",
      "uals remain at the full input resolution throughout the net-\n",
      "work. A natural baseline is thus a traditional ResNet en-\n",
      "coder/decoder architecture with long-range skip connec-\n",
      "tions [38, 41]. In fact, such an architecture resembles a\n",
      "single deep hourglass module in the stacked hourglass net-\n",
      "work architecture [40]. This baseline differs from our pro-\n",
      "posed architecture in two important ways: While the feature\n",
      "maps on our residual stream are processed by each FRRU,\n",
      "the feature maps on the long-range skip connections are not\n",
      "processed by intermediate layers. Furthermore, long-range\n",
      "skip connections are scale dependent, meaning that features\n",
      "at one scale travel over a different skip connection than fea- \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.86806476 ﬁne-grained information from the downsampling layers.\n",
      "Among CNN architectures extended as FCNs for seman-\n",
      "tic segmentation purposes, Residual Networks (ResNets)\n",
      "[11] make an interesting case. ResNets are designed to\n",
      "ease the training of very deep networks (of hundreds of\n",
      "layers) by introducing a residual block that sums two sig-\n",
      "nals: a non-linear transformation of the input and its identity\n",
      "mapping. The identity mapping is implemented by means \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.86715066 3.2. Network Architecture\n",
      "Using the SK convolutions, the overall SKNet architec-\n",
      "ture is listed in Table 1. We start from ResNeXt [47] for\n",
      "two reasons: 1) it has low computational cost with extensive\n",
      "use of grouped convolution, and 2) it is one of the state-of-\n",
      "the-art network architectures with high performance on ob-\n",
      "ject recognition. Similar to the ResNeXt [47], the proposed\n",
      "SKNet is mainly composed of a stack of repeated bottle-\n",
      "neck blocks, which are termed “SK units”. Each SK unit\n",
      "consists of a sequence of 1 ×1 convolution, SK convolu-\n",
      "tion and 1 ×1 convolution. In general, all the large kernel\n",
      "convolutions in the original bottleneck blocks in ResNeXt\n",
      "are replaced by the proposed SK convolutions, enabling the\n",
      "network to choose appropriate RF sizes in an adaptive man-\n",
      "ner. As the SK convolutions are very efﬁcient in our design,\n",
      "SKNet-50 only leads to 10% increase in the number of pa-\n",
      "rameters and 5% increase in computational cost, compared\n",
      "with ResNeXt-50. \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n",
      "0.86700374 multi-branch architecture where each branch is customized carefully. While a\n",
      "naive increase in depth comes to saturation due to the diﬃculty of gradient\n",
      "propagation, ResNet [5] proposes a simple identity skip-connection to ease the\n",
      "optimization issues of deep networks. Based on the ResNet architecture, various\n",
      "modelssuchasWideResNet[6],Inception-ResNet[8],andResNeXt[7]havebeen\n",
      "developed. WideResNet [6] proposes a residual network with a larger number of\n",
      "convolutionalﬁltersandreduceddepth.PyramidNet[20]isastrictgeneralization\n",
      "of WideResNet where the width of the network gradually increases. ResNeXt [7]\n",
      "suggests to use grouped convolutions and shows that increasing the cardinality\n",
      "leads to better classiﬁcation accuracy. More recently, Huanget al. [21] propose\n",
      "a new architecture, DenseNet. It iteratively concatenates the input features with\n",
      "the output features, enabling each convolution block to receive raw information \n",
      "#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sep=\"\\n#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$#$\\n\"\n",
    "[print(p.score,p.payload['text'],sep) for p in search(\"what is the resnet architecture?\",limit=10).points];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea827e-8192-40e5-94a8-3ff841f5c249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
